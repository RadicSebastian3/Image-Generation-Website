<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image-Generators</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">  >
</head>
<body>
    <section id="s0"></section>

    <div id="navbar">
        <a href="index.html">Was ist Image Generation?</a>
        <a href="how-it-works.html">Wie Image Generation funktioniert</a>
    </div>
    <div id="space"></div>

    <div id="google_translate_element"><script>
        function googleTranslateElementInit() {
          new google.translate.TranslateElement({
            pageLanguage: 'de'
          }, 'google_translate_element');
        }
        </script><script src="http://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
    </div>


    <div id="sections">
        <a href="#s1">Stable Diffusion</a>
        <a href="#s2">Craiyon</a>
        <a href="#s3">Dall-E 2</a>
        <a href="#s4">Midjourney</a>
    </div>
    
    <h1>Die verschiedenen Image Generators</h1>

    <section id="s1">
        <h2>Stable Diffusion</h2>
        <p>Stable Diffusion ist die Inspiration hinter diesem Artikel und ein Tool, mit dem ich persönlich in letzter Zeit viel herumgespielt habe. 
            Es läuft lokal auf Ihrem Computer (Sie kämpfen also nicht mit anderen Benutzern eines Online-Tools um Ressourcen) und ist eines der leistungsstärksten, die Sie derzeit verwenden können.
            Sie können damit nicht nur eine Menge Parameter feinabstimmen, sondern auch den gesamten Generierungsprozess steuern.</p>
        <p>Stable Diffusion leidet unter all den gleichen KI-Fallstricken, mit der zusätzlichen „Gefahr“ der Zugänglichkeit. 
            Jeder mit einem ausreichend leistungsfähigen Computer kann ihn einrichten und schnell zum Laufen bringen.
            Für schlechtere Hardware wird die Zugänglichkeit jedoch schwierig.</p>
        <p>Das Beste an Stable Diffusion ist, dass es vollständig Open Source ist. Sie können die Unterstützung dafür heute in jedes Ihrer Projekte implementieren, wenn Sie möchten, und es gibt bereits Plugins wie Alpaca, die Sie zur Integration in Photoshop verwenden können.
            Es ist noch nicht perfekt, aber es ist extrem früh in der Entwicklung dieser Programme. 
            Sie können Dream Studio auch verwenden, wenn Sie möchten, obwohl dies Geld kostet und im Vergleich zur lokalen Einrichtung etwas restriktiv ist.</p>
        <p>Wenn Sie Stable Diffusion lokal einrichten, gibt es darüber hinaus Forks wie die Stable Diffusion WebUI von AUTOMATIC1111, die mit einem integrierten Upscale-Tool ausgestattet sind, das die Auflösung bis zu viermal erhöhen kann. 
            Sie können zwar Bilder mit höheren Auflösungen generieren, es ist jedoch oft viel schneller, ein Bild mit einer niedrigeren Auflösung zu generieren und es dann hochzuskalieren.
            Alle Bilder unten sind von kleineren Auflösungen hochskaliert.</p>
        <blockquote>Stable Diffusion wurde auf einem Cluster von 4.000 Nvidia A100-GPUs trainiert, die in AWS ausgeführt wurden, und fand über einen Monat statt. Es kann Bilder von Prominenten generieren und verfügt außerdem über einen integrierten NSFW-Filter. 
            Sie können diesen NSFW-Filter bei lokalen Installationen deaktivieren, da er tatsächlich Ressourcen spart, indem er die VRAM-Nutzung verringert. Was "Diffusion" bedeutet, ist der Prozess, mit reinem Rauschen zu beginnen und sich im Laufe der Zeit zu verfeinern. 
            Dadurch wird das Bild im Laufe der Zeit schrittweise näher an die Textaufforderung herangeführt, bis kein Rauschen mehr vorhanden ist. Auf die gleiche Weise funktioniert Dall-E 2.</blockquote>
        <p>Ein weiteres lustiges Feature von Stable Diffusion ist "img2img". 
            In diesem geben Sie ihm ein Bild als Eingabeaufforderung, beschreiben, was das Bild sein soll, und lassen sich dann eine richtige Zeichnung geben.</p>
        
        <a target="_blank" class="image" href="https://cdn.pixabay.com/photo/2022/11/02/10/13/landscape-7564520_1280.jpg">
            <img src="https://cdn.pixabay.com/photo/2022/11/02/10/13/landscape-7564520_1280.jpg" 
        alt="Stable Diffusion Example"></a>
        <p class="credit">Image Source: Pixabay</p>
    </section>

    <section id="s2">
        <h2>Craiyon</h2>
        <p>Craiyon war früher als DALL·E Mini bekannt, obwohl es trotz des Namens nichts mit Dall-E 2 zu tun hat. Es wurde entwickelt, um die Ergebnisse des DALL·E-Text-zu-Bild-Modells von OpenAI zu reproduzieren.
            Craiyon steht der Öffentlichkeit zur Verfügung und kann verwendet werden, um Bilder zu erzeugen, die überraschend anständig sind, obwohl die Bilder weder so genau noch so hochwertig sind. 
            Die maximale Bildauflösung liegt bei 256 x 256, und es gibt auch keine Upscaling-Tools.</p>
        <p>Craiyon kann völlig kostenlos verwendet werden und ist über seine Website zugänglich. 
            Sie können jedes Bild über jede Eingabeaufforderung generieren, und der einzige Haken ist, dass die Bilder von geringerer Qualität sind und Sie etwa zwei Minuten auf jeden generierten Stapel von Bildern warten müssen. 
            Craiyon begann als Open-Source-Modell mit dem Ziel, die Ergebnisse des ursprünglichen DALL·E-Modells zu reproduzieren. 
            Das jetzt verwendete Modell ist als DALL·E Mega bekannt und enthält mehrere Verbesserungen.</p>
        <p>Craiyon wird im Gegensatz zu den anderen Optionen hier durch Werbeeinnahmen unterstützt. 
            Infolgedessen sehen Sie bei Ihrem Besuch bezahlte Sponsoring- und andere Anzeigen auf ihrer Website. 
            Auch für Android-Smartphones gibt es eine App. Es ist nicht das raffinierteste, aber es macht Spaß, ist einfach zu bedienen und zugänglich.</p>

        <a target="_blank" class="image" href="https://i.ibb.co/kJDzHvp/image.png">
            <img src="https://i.ibb.co/kJDzHvp/image.png" 
        alt="Craiyon Example"></a>
        <p class="credit">Image Source: Craiyon</p>
    </section>

    <section id="s3">
        <h2>Dall-E 2</h2>
        <p>Dall-E 2 ist ein Produkt des OpenAI-Forschungslabors und der bekannteste KI-Bildgenerator, an den die Leute denken.
            Es ist ein geschlossenes Tool mit eingeschränktem Zugriff, aber für diejenigen, die darauf zugreifen können, sind einige der Ergebnisse, die es erzielen kann, unglaublich. 
            Es wurde ursprünglich aufgrund von Bedenken hinsichtlich der Ethik und Sicherheit eines solchen Tools geschlossen, obwohl es im Laufe der Zeit schrittweise erweitert wurde.</p>
        <p>Einer der größten Vorteile von Dall-E 2 ist die Fähigkeit, fotorealistische Bilder zu erstellen, die auf den ersten Blick nicht von echten Fotos zu unterscheiden sind. 
            Es kann Gemälde, Bilder, die aussehen, als wären sie mit echten Kameras aufgenommen worden, und vollständig erfundene Szenarien erzeugen. 
            Als es zum ersten Mal angekündigt wurde, stellte es einen großen Sprung in den Fähigkeiten der KI dar, sowohl in seiner Fähigkeit, Bilder zu erstellen, als auch in seiner Verarbeitung natürlicher Sprache, bekannt als NLP. 
            Dies ist der Implementierung von GPT-3 zu verdanken, das eines der fortschrittlichsten Sprachmodelle auf dem Markt ist und ebenfalls von OpenAI verfasst wurde.</p>
        <p>Genau wie bei Stable Diffusion hat auch Dall-E 2 seine eigene Fähigkeit, vorhandene Bilder aufzunehmen und sie basierend auf einer Aufforderung zu ändern. 
            Sie können Fotos damit bearbeiten, indem Sie es bitten, etwas zu einem Bild hinzuzufügen, oder es sogar bitten, etwas zu entfernen oder die Beleuchtung zu ändern. 
            Während es nur quadratische Bilder erstellt, hat OpenAI letzten Monat Outpainting angekündigt , das Ihre Bilder breiter erweitern kann, wobei der Kontext dessen berücksichtigt wird, was bereits in Ihrem quadratischen Bild verfügbar ist.</p>
        <p>Dall-E 2 steht allen zum Ausprobieren zur Verfügung.</p>

        <a target="_blank" class="image" href="https://www.trustedreviews.com/wp-content/uploads/sites/54/2022/10/Dall-E-2-image-exmaple-soup-912x912.jpg">
            <img src="https://www.trustedreviews.com/wp-content/uploads/sites/54/2022/10/Dall-E-2-image-exmaple-soup-912x912.jpg"
        alt="Dall-E Example"></a>

        <p class="credit">Image Source: Trusted Reviews</p>
    </section>

    <section id="s4">
        <h2>Midjourney</h2>
        <p>Midjourney ist interessant, da es sich um eine öffentliche Plattform handelt, die Bilder generieren kann, obwohl Sie dies über einen Discord-Server tun. 
            Nicht nur das, sondern nachdem Sie 25 Bilder generiert haben, müssen Sie den Dienst abonnieren, um weiterhin neue zu generieren.</p>
        <p>Während Midjourney hier wahrscheinlich die am besten zugängliche Plattform ist (vorausgesetzt, Sie können von jedem Gerät mit einem Discord-Konto darauf zugreifen), kostet es Sie auch Geld. 
            Dafür bekommt man aber Qualität. Ein Benutzer des Dienstes, Jason Allen, schuf ein Stück, das er "Théâtre D'opéra Spatial" nannte. 
            Er nahm damit am Kunstwettbewerb der Colorado State Fair teil und gewann.</p>
        <p>Im Gegensatz zu diesen anderen Projekten ist Midjourney ein proprietäres Programm für künstliche Intelligenz. 
            Es gibt keinen Quellcode, den Sie einsehen können, und sein gesamter Zweck ist zu diesem Zeitpunkt auf die Verwendung innerhalb eines Discord-Servers beschränkt.</p>
    
            <a target="_blank" class="image" href="https://cdn.pixabay.com/photo/2022/09/13/05/30/midjourney-7450984_1280.jpg">
                <img src="https://cdn.pixabay.com/photo/2022/09/13/05/30/midjourney-7450984_1280.jpg" 
            alt="Midjourney Example"></a>
            <p class="credit">Image Source: Pixabay</p>
    </section>
            
    <div id="back-to-top">
        <a href="#s0">Zurück zum Anfang</a>
    </div>
</body>
</html>